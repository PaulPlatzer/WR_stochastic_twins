{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Notebook 4 : Dimensions computation </center></h1>\n",
    "\n",
    "<h2>Instructions for this notebook</h2>\n",
    "\n",
    "\n",
    "This notebook was written by Paul Platzer. It accompanies the following scientific publication:<br>\n",
    "\"Disentangling Density and Geometry in Weather Regime Dimensions using Stochastic Twins\"<br>\n",
    "By Paul Platzer, Bertrand Chapron, and Gabriele Messori.<br>\n",
    "<b> add doi, date...etc. </b>\n",
    "\n",
    "It is part of six notebooks that allow to reproduce the figures of the article. It must be used in conjunction with 500mb geopotential height data from ERA5 (last download from october 18th, 2023), as specified in the body text of the article.\n",
    "\n",
    "What this notebook does:\n",
    "\n",
    "<ol>\n",
    "    <li> It opens raw ERA5 data and climatology, and recomputes anomaly as well as 10 days running-window time-smoothing.</li>\n",
    "    <li> It opens preprocessed ERA5 data (10day-smoothed anomalies projected on winter-time EOFs), the results of the GMM fit, and the stochastic twins.</li>\n",
    "    <li> It computes weather-regime indices based on ERA5 projected data, stochastic twin data, and GMM fit parameters. </li>\n",
    "    <li> It computes dimension in various ways, with either only ERA5 data (projected or not on EOFs), or with ERA5 and stochastic twins, or with only stochastic twins, as outlined in the paper. </li>\n",
    "    <li> It saves computed dimensions. </li>\n",
    "</ol>\n",
    "\n",
    "To use properly this notebook, you must:\n",
    "\n",
    "<ol>\n",
    "    <li> Have previously run \"Notebook0-ERA5_pretreatment.ipynb\", \"Notebook1-GMM_fit.ipynb\" and \"Notebook2-Stochastic_twin_generation.ipynb\".</li>\n",
    "    <li> Run the whole notebook once.</li>\n",
    "    <li> If you have already run the notebook, and you just want to replot the figures, you can skip section III. </li>\n",
    "</ol>\n",
    "\n",
    "Note that, for this code to work on your machine, you should:\n",
    "\n",
    "<ol>\n",
    "    <li> Have download the libraries listed in the first two cells. </li>\n",
    "    <li> Use python 3 : this code was tested using python 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0] </li>\n",
    "    <li> Have enough memory and computing resources. If not, you might have to modify the code to make it work. The code was run using a Dell Inc. Precision 7550 which has 33G of RAM and setting the same amount of swap space, and for processing we have Intel® Core™ i7-10875H CPU @ 2.30GHz × 16, with graphics card NVIDIA Corporation TU104GLM [Quadro RTX 4000 Mobile / Max-Q] / Mesa Intel® UHD Graphics (CML GT2). </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.neighbors import KDTree, NearestNeighbors\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import sys\n",
    "sys.path.append('../functions/.')\n",
    "from functions import locdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['k', '#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../outputs/data/'\n",
    "figure_folder = '../outputs/figures/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Load ERA5 + climatology and recompute anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_folder = '/home/pplatzer/Documents/pro/postdoc/DATA/ERA5/'\n",
    "file = 'ERA5_z500_1979_2023.grib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(ERA5_folder+file, engine='cfgrib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load climatology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_clim = xr.open_dataset(ERA5_folder + 'ERA5_z500_clim_1979_2023.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute anomaly (may take some time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.assign_coords(dayofyear=ds['time'].dt.dayofyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing anomaly from time 1979-01-01T00:00:00.000000000 to 1980-12-31T00:00:00.000000000\n",
      "Computing anomaly from time 1980-12-31T00:00:00.000000000 to 1982-12-31T00:00:00.000000000\n",
      "Computing anomaly from time 1982-12-31T00:00:00.000000000 to 1984-12-30T00:00:00.000000000\n",
      "Computing anomaly from time 1984-12-30T00:00:00.000000000 to 1986-12-30T00:00:00.000000000\n",
      "Computing anomaly from time 1986-12-30T00:00:00.000000000 to 1988-12-29T00:00:00.000000000\n",
      "Computing anomaly from time 1988-12-29T00:00:00.000000000 to 1990-12-29T00:00:00.000000000\n",
      "Computing anomaly from time 1990-12-29T00:00:00.000000000 to 1992-12-28T00:00:00.000000000\n",
      "Computing anomaly from time 1992-12-28T00:00:00.000000000 to 1994-12-28T00:00:00.000000000\n",
      "Computing anomaly from time 1994-12-28T00:00:00.000000000 to 1996-12-27T00:00:00.000000000\n",
      "Computing anomaly from time 1996-12-27T00:00:00.000000000 to 1998-12-27T00:00:00.000000000\n",
      "Computing anomaly from time 1998-12-27T00:00:00.000000000 to 2000-12-26T00:00:00.000000000\n",
      "Computing anomaly from time 2000-12-26T00:00:00.000000000 to 2002-12-26T00:00:00.000000000\n",
      "Computing anomaly from time 2002-12-26T00:00:00.000000000 to 2004-12-25T00:00:00.000000000\n",
      "Computing anomaly from time 2004-12-25T00:00:00.000000000 to 2006-12-25T00:00:00.000000000\n",
      "Computing anomaly from time 2006-12-25T00:00:00.000000000 to 2008-12-24T00:00:00.000000000\n",
      "Computing anomaly from time 2008-12-24T00:00:00.000000000 to 2010-12-24T00:00:00.000000000\n",
      "Computing anomaly from time 2010-12-24T00:00:00.000000000 to 2012-12-23T00:00:00.000000000\n",
      "Computing anomaly from time 2012-12-23T00:00:00.000000000 to 2014-12-23T00:00:00.000000000\n",
      "Computing anomaly from time 2014-12-23T00:00:00.000000000 to 2016-12-22T00:00:00.000000000\n",
      "Computing anomaly from time 2016-12-22T00:00:00.000000000 to 2018-12-22T00:00:00.000000000\n",
      "Computing anomaly from time 2018-12-22T00:00:00.000000000 to 2020-12-21T00:00:00.000000000\n",
      "Computing anomaly from time 2020-12-21T00:00:00.000000000 to 2022-12-21T00:00:00.000000000\n",
      "Computing anomaly from time 2022-12-21T00:00:00.000000000 to 2024-12-20T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "z_anom = ds['z'].copy()\n",
    "dt_comp = np.timedelta64(int(2*365),'D')\n",
    "t0 = ds.time[0]\n",
    "while t0 < ds.time[-1]:\n",
    "    t1 = t0.copy() + dt_comp\n",
    "    print('Computing anomaly from time '+str(np.array(t0))+' to '+str(np.array(t1)))\n",
    "          \n",
    "    z_anom.loc[t0:t1] = ( ds['z'].sel(time=slice(t0,t1)) - ds_clim['z'].sel(dayofyear=ds['dayofyear'].sel(time=slice(t0,t1))) ).values\n",
    "    t0 += dt_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-smoothing (may take some time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "za_smooth = z_anom.rolling(time=2*10, center=True).mean().dropna('time') # 10 days rolling average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Load preprocessed ERA5, GMM parameters, and stochastic twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "smooth = True\n",
    "npzfile = np.load(data_folder + 'GMM_params_' + smooth*'smooth' + (1-smooth)*'unsmooth' + '.npz')\n",
    "means = npzfile['means']\n",
    "covs = npzfile['covs']\n",
    "weights = npzfile['weights']\n",
    "nclus = npzfile['nclus']\n",
    "cov_type = npzfile['cov_type']\n",
    "ndim_gmm = npzfile['ndim_gmm']\n",
    "random_state_gmm = npzfile['random_state_gmm']\n",
    "regime_names = npzfile['regime_names']\n",
    "regime_short_names = npzfile['regime_short_names']\n",
    "regime_attribution = npzfile['regime_attribution']\n",
    "regime_attribution_distance = npzfile['regime_attribution_distance']\n",
    "Ndays = npzfile['Ndays']\n",
    "Ndays_kmeans = npzfile['Ndays_kmeans']\n",
    "Ndays_tot = npzfile['Ndays_tot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpcs = xr.open_dataset(data_folder + 'pcs_' + smooth*'smooth' + (1-smooth)*'unsmooth' + '.nc')['pseudo_pcs']\n",
    "eofs = xr.open_dataset(data_folder + 'eofs_' + smooth*'smooth' + (1-smooth)*'unsmooth' + '.nc')['eofs']\n",
    "pourc_EOF = xr.open_dataset(data_folder + 'pourc_eofs_' + smooth*'smooth' + (1-smooth)*'unsmooth' + '.nc')['variance_fractions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize pcs but keep relative variances\n",
    "pcs_norm = allpcs / (allpcs.sel(mode=0)).std(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load(data_folder + 'stoch_twins.npz')\n",
    "X = npzfile['X']\n",
    "ndim_gmm = npzfile['ndim_gmm']\n",
    "rho = npzfile['rho']\n",
    "scaling = npzfile['scaling']\n",
    "Ntwins = X.shape[0]\n",
    "L = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Compute weather regime index (WRI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.zeros( ( Ntwins , L , len(means) ) ,  dtype='float64')\n",
    "for k in range(Ntwins):\n",
    "    for i in range(len(means)):\n",
    "        index[k,:,i] = np.sum( X[k][:,:ndim_gmm]*means[i] , axis=1)\n",
    "        index[k,:,i] -= np.mean( index[k,:,i] )\n",
    "        index[k,:,i] /= np.std( index[k,:,i] )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_index = np.zeros( ( Ntwins , L , len(means) ) ,  dtype='float64')\n",
    "for k in range(Ntwins):\n",
    "    for i in range(len(means)):\n",
    "        c_index[k,:,i] = np.einsum( 'ij,jk,ik->i' , X[k][:,:ndim_gmm]-means[i] ,\n",
    "                                   np.linalg.inv(covs[i]) , X[k][:,:ndim_gmm]-means[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_nat = np.zeros( ( len(pcs_norm), len(means) ) ,  dtype='float64')\n",
    "for i in range(len(means)):\n",
    "    index_nat[:,i] = np.sum( np.array(pcs_norm[:,:ndim_gmm])*means[i] , axis=1)\n",
    "    index_nat[:,i] -= np.mean( index_nat[:,i] )\n",
    "    index_nat[:,i] /= np.std( index_nat[:,i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_index_nat = np.zeros( ( len(pcs_norm) , len(means) ) ,  dtype='float64')\n",
    "for i in range(len(means)):\n",
    "    c_index_nat[:,i] = np.einsum( 'ij,jk,ik->i' , pcs_norm[:,:ndim_gmm]-means[i] ,\n",
    "                                 np.linalg.inv(covs[i]) , pcs_norm[:,:ndim_gmm]-means[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Compute dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.A. Using only natural ERA5 data\n",
    "First whole z500 fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# za_djf = np.reshape( np.array(z_anom.isel(time = (z_anom.time.dt.season == 'DJF'))),\n",
    "#                    (np.array(z_anom.time.dt.season == 'DJF').sum(),len(z_anom.latitude)*len(z_anom.longitude)))\n",
    "za_djf = np.reshape( np.array(za_smooth.isel(time = (za_smooth.time.dt.season == 'DJF'))),\n",
    "                   (np.array(za_smooth.time.dt.season == 'DJF').sum(),len(za_smooth.latitude)*len(za_smooth.longitude)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find analogues with KDTree\n",
    "Klarge = 500\n",
    "nn = NearestNeighbors(n_neighbors = Klarge).fit( za_djf )\n",
    "dist_nat, ind_nat = nn.kneighbors( za_djf , return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac4145dbbad4160b029945e4c2f33e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define multiple Ks for the computation of dimensions\n",
    "K = np.arange(150 , Klarge + 10 , 10)\n",
    "\n",
    "dd_nat = np.full( ( L , len(K) ) , np.nan )\n",
    "for i_K in tqdm(range(len(K))):\n",
    "    dd_nat[:,i_K] = locdim(dist_nat[:,1:1+K[i_K]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then projected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find neighbours using KDTree\n",
    "nn = NearestNeighbors(n_neighbors = Klarge).fit( pcs_norm )\n",
    "dist_pcs, ind_pcs = nn.kneighbors( pcs_norm , return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4baaf75287d34a6cba2ccc9030b72662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd_pcs = np.full( ( L , len(K) ) , np.nan )\n",
    "for i_K in tqdm(range(len(K))):\n",
    "    dd_pcs[:,i_K] = locdim(dist_pcs[:,1:1+K[i_K]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save if needed\n",
    "np.savez(data_folder + 'dim_nat.npz',\n",
    "        dd_nat = dd_nat,\n",
    "        dd_pcs = dd_pcs,\n",
    "         K = K,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load if needed\n",
    "# npzfile = np.load(data_folder + 'dim_nat.npz')\n",
    "# dd_nat = npzfile['dd_nat']\n",
    "# dd_pcs = npzfile['dd_pcs']\n",
    "# K = npzfile['K']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.A. Stochastic twin analogues\n",
    "First, as target *and* analogues.<br>\n",
    "Then, only as analogues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481d29a6e0444c3bbfa0110e532f3bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first find neighbours\n",
    "DIST_twin = []; IND_twin = []\n",
    "DIST_nat_twin = []; IND_nat_twin = []\n",
    "\n",
    "for k in tqdm(range(Ntwins)):\n",
    "    nn = NearestNeighbors(n_neighbors = Klarge+1 ).fit( X[k] )\n",
    "    # twins as target and analogues or as analogues\n",
    "    for i_type in range(2):\n",
    "        dist, ind = nn.kneighbors( [ X[k] , pcs_norm ][i_type] , return_distance=True)\n",
    "        if i_type == 0:\n",
    "            DIST_twin.append( dist )\n",
    "            IND_twin.append( ind )\n",
    "        else:\n",
    "            DIST_nat_twin.append( dist )\n",
    "            IND_nat_twin.append( ind )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa22fea04345448aa16568016c40fe06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ab9482b6b545e4bf9c29415c256af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1983f75a00e414dbde97c244f79a23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f7db56621944a2890fbf94223c6a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4270d8eb974849aace7c767d6264bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526fe23a6d7b4c8ea7199f8867557d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cd40929d944db8817e4c3f9eaa3e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64faf35045e42ff970b1624fe80fecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fec848184ed4a7abe26c16402e2e811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd3dffa987940eeae1a9eb1104160f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0008b893f3df4bfba04cddd6ef0d30c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8f1265cf3d45a990520eaa6a301d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5b6c384f284613bf1775c665bb9e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6221a87cd1403aa2155d9c44806953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f501373e124a29ab1805e089d5b9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e600565ac8224a6b8062b812e488c2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23c68492be8459799b5ee899d41fb2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd2719da0024b42828802027e7fd85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b3cc50bdf94f27b6d24bac4a83b2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4ad4945b4240e9967c9a781b022069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecfd6224e8644c98668bd19b0d62a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# then compute dimensions\n",
    "dd_twin = np.full( ( Ntwins , L , len(K) ) , np.nan )\n",
    "dd_nat_twin = np.full( ( Ntwins , L , len(K) ) , np.nan )\n",
    "\n",
    "for k in tqdm(range(Ntwins)):\n",
    "    for i_K in tqdm(range(len(K))):\n",
    "        dd_twin[k,:,i_K] = locdim(DIST_twin[k][:,1:1+K[i_K]])        \n",
    "        dd_nat_twin[k,:,i_K] = locdim(DIST_nat_twin[k][:,0:K[i_K]])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save if needed\n",
    "np.savez(data_folder + 'dim_twins.npz',\n",
    "        dd_nat_twin = dd_nat_twin,\n",
    "        dd_twin = dd_twin,\n",
    "        K = K,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load if needed\n",
    "# npzfile = np.load(data_folder + 'dim_twins.npz')\n",
    "# dd_nat_twin = npzfile['dd_nat_twin']\n",
    "# dd_twin = npzfile['dd_twin']\n",
    "# K = npzfile['K']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
